{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain (from -r requirements.txt (line 1))\n",
      "  Using cached langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langgraph (from -r requirements.txt (line 2))\n",
      "  Using cached langgraph-0.2.74-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pandas (from -r requirements.txt (line 3))\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 4))\n",
      "  Using cached numpy-2.2.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy (from -r requirements.txt (line 5))\n",
      "  Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting matplotlib (from -r requirements.txt (line 6))\n",
      "  Using cached matplotlib-3.10.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting ollama (from -r requirements.txt (line 7))\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting duckduckgo-search (from -r requirements.txt (line 8))\n",
      "  Using cached duckduckgo_search-7.4.4-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting semantic-router (from -r requirements.txt (line 9))\n",
      "  Using cached semantic_router-0.0.20-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pydantic (from -r requirements.txt (line 10))\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting torch (from -r requirements.txt (line 11))\n",
      "  Using cached torch-2.6.0-cp313-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting kaggle (from -r requirements.txt (line 12))\n",
      "  Using cached kaggle-1.6.17-py3-none-any.whl\n",
      "Collecting openai (from -r requirements.txt (line 13))\n",
      "  Using cached openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting llama-index (from -r requirements.txt (line 14))\n",
      "  Downloading llama_index-0.12.19-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached langchain_core-0.3.37-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached langsmith-0.3.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached SQLAlchemy-2.0.38-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.6 kB)\n",
      "Collecting requests<3,>=2 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiohttp-3.11.12-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain->-r requirements.txt (line 1))\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph->-r requirements.txt (line 2))\n",
      "  Using cached langgraph_checkpoint-2.0.16-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph->-r requirements.txt (line 2))\n",
      "  Using cached langgraph_sdk-0.1.53-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hassaanulhaq/Library/Mobile Documents/com~apple~CloudDocs/Hacklytics/hacklytics_25/.venv/lib/python3.13/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->-r requirements.txt (line 3))\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->-r requirements.txt (line 3))\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached fonttools-4.56.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (101 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hassaanulhaq/Library/Mobile Documents/com~apple~CloudDocs/Hacklytics/hacklytics_25/.venv/lib/python3.13/site-packages (from matplotlib->-r requirements.txt (line 6)) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->-r requirements.txt (line 6))\n",
      "  Using cached pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting httpx<0.29,>=0.27 (from ollama->-r requirements.txt (line 7))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting click>=8.1.8 (from duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting lxml>=5.3.0 (from duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached lxml-5.3.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (3.7 kB)\n",
      "Collecting black<24.0.0,>=23.12.1 (from semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached black-23.12.1-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting cohere<5.0,>=4.32 (from semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached cohere-4.57-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting colorlog<7.0.0,>=6.8.0 (from semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 4))\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->-r requirements.txt (line 10))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic->-r requirements.txt (line 10))\n",
      "  Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.12.2 (from pydantic->-r requirements.txt (line 10))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting filelock (from torch->-r requirements.txt (line 11))\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting networkx (from torch->-r requirements.txt (line 11))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->-r requirements.txt (line 11))\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch->-r requirements.txt (line 11))\n",
      "  Using cached fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting setuptools (from torch->-r requirements.txt (line 11))\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch->-r requirements.txt (line 11))\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->-r requirements.txt (line 11))\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: six>=1.10 in /Users/hassaanulhaq/Library/Mobile Documents/com~apple~CloudDocs/Hacklytics/hacklytics_25/.venv/lib/python3.13/site-packages (from kaggle->-r requirements.txt (line 12)) (1.17.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle->-r requirements.txt (line 12))\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting tqdm (from kaggle->-r requirements.txt (line 12))\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle->-r requirements.txt (line 12))\n",
      "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3 (from kaggle->-r requirements.txt (line 12))\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle->-r requirements.txt (line 12))\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 13))\n",
      "  Using cached anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 13))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r requirements.txt (line 13))\n",
      "  Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 13))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting llama-index-agent-openai<0.5.0,>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl.metadata (727 bytes)\n",
      "Collecting llama-index-cli<0.5.0,>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_cli-0.4.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.13.0,>=0.12.19 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_core-0.12.19-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.4.0,>=0.3.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-llms-openai<0.4.0,>=0.3.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_llms_openai-0.3.20-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.5.0,>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl.metadata (726 bytes)\n",
      "Collecting llama-index-program-openai<0.4.0,>=0.3.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_program_openai-0.3.1-py3-none-any.whl.metadata (764 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.4.0,>=0.3.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl.metadata (783 bytes)\n",
      "Collecting llama-index-readers-file<0.5.0,>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_readers_file-0.4.5-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting nltk>3.8.1 (from llama-index->-r requirements.txt (line 14))\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached attrs-25.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 1))\n",
      "  Using cached yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (69 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 13))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mypy-extensions>=0.4.3 (from black<24.0.0,>=23.12.1->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pathspec>=0.9.0 (from black<24.0.0,>=23.12.1->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /Users/hassaanulhaq/Library/Mobile Documents/com~apple~CloudDocs/Hacklytics/hacklytics_25/.venv/lib/python3.13/site-packages (from black<24.0.0,>=23.12.1->semantic-router->-r requirements.txt (line 9)) (4.3.6)\n",
      "Collecting backoff<3.0,>=2.0 (from cohere<5.0,>=4.32->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting fastavro<2.0,>=1.8 (from cohere<5.0,>=4.32->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached fastavro-1.10.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.5 kB)\n",
      "Collecting importlib_metadata<7.0,>=6.0 (from cohere<5.0,>=4.32->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.27->ollama->-r requirements.txt (line 7))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.29,>=0.27->ollama->-r requirements.txt (line 7))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting brotli (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl.metadata (5.5 kB)\n",
      "Collecting h2<5,>=3 (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.35->langchain->-r requirements.txt (line 1))\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->-r requirements.txt (line 2))\n",
      "  Using cached msgpack-1.1.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.4 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.2.0,>=0.1.42->langgraph->-r requirements.txt (line 2))\n",
      "  Using cached orjson-3.10.15-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 1))\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain->-r requirements.txt (line 1))\n",
      "  Using cached zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/hassaanulhaq/Library/Mobile Documents/com~apple~CloudDocs/Hacklytics/hacklytics_25/.venv/lib/python3.13/site-packages (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14)) (1.6.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting wrapt (from llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting llama-cloud<0.2.0,>=0.1.13 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_cloud-0.1.13-py3-none-any.whl.metadata (800 bytes)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_parse-0.6.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting joblib (from nltk>3.8.1->llama-index->-r requirements.txt (line 14))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain->-r requirements.txt (line 1))\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting webencodings (from bleach->kaggle->-r requirements.txt (line 12))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r requirements.txt (line 11))\n",
      "  Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle->-r requirements.txt (line 12))\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.5.0,>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->duckduckgo-search->-r requirements.txt (line 8))\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting zipp>=0.5 (from importlib_metadata<7.0,>=6.0->cohere<5.0,>=4.32->semantic-router->-r requirements.txt (line 9))\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain->-r requirements.txt (line 1))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting llama-cloud-services>=0.6.1 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading llama_cloud_services-0.6.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading greenlet-3.1.1-cp313-cp313-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.13.0,>=0.12.19->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from llama-cloud-services>=0.6.1->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r requirements.txt (line 14))\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "Using cached langgraph-0.2.74-py3-none-any.whl (151 kB)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached scipy-1.15.2-cp313-cp313-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached matplotlib-3.10.0-cp313-cp313-macosx_11_0_arm64.whl (8.0 MB)\n",
      "Using cached ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Using cached duckduckgo_search-7.4.4-py3-none-any.whl (35 kB)\n",
      "Using cached semantic_router-0.0.20-py3-none-any.whl (33 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Using cached pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached torch-2.6.0-cp313-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Downloading llama_index-0.12.19-py3-none-any.whl (7.0 kB)\n",
      "Using cached aiohttp-3.11.12-cp313-cp313-macosx_11_0_arm64.whl (453 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Using cached black-23.12.1-py3-none-any.whl (194 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached cohere-4.57-py3-none-any.whl (52 kB)\n",
      "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Using cached contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached fonttools-4.56.0-cp313-cp313-macosx_10_13_universal2.whl (2.7 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached socksio-1.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached jiter-0.8.2-cp313-cp313-macosx_11_0_arm64.whl (309 kB)\n",
      "Using cached kiwisolver-1.4.8-cp313-cp313-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached langchain_core-0.3.37-py3-none-any.whl (413 kB)\n",
      "Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Using cached langgraph_checkpoint-2.0.16-py3-none-any.whl (38 kB)\n",
      "Using cached langgraph_sdk-0.1.53-py3-none-any.whl (45 kB)\n",
      "Using cached langsmith-0.3.10-py3-none-any.whl (333 kB)\n",
      "Downloading llama_index_agent_openai-0.4.6-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.12.19-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.6.8-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_llms_openai-0.3.20-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.4.3-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.3.1-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.3.0-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.4.5-py3-none-any.whl (39 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl (2.5 kB)\n",
      "Using cached lxml-5.3.1-cp313-cp313-macosx_10_13_universal2.whl (8.2 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pillow-11.1.0-cp313-cp313-macosx_11_0_arm64.whl (3.1 MB)\n",
      "Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached SQLAlchemy-2.0.38-cp313-cp313-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl (195 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached fastavro-1.10.0-cp313-cp313-macosx_10_13_universal2.whl (1.0 MB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached frozenlist-1.5.0-cp313-cp313-macosx_11_0_arm64.whl (50 kB)\n",
      "Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading llama_cloud-0.1.13-py3-none-any.whl (253 kB)\n",
      "Downloading llama_parse-0.6.1-py3-none-any.whl (4.8 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached msgpack-1.1.0-cp313-cp313-macosx_11_0_arm64.whl (81 kB)\n",
      "Using cached multidict-6.1.0-cp313-cp313-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached orjson-3.10.15-cp313-cp313-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Using cached propcache-0.3.0-cp313-cp313-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-macosx_11_0_arm64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached yarl-1.18.3-cp313-cp313-macosx_11_0_arm64.whl (91 kB)\n",
      "Using cached zstandard-0.23.0-cp313-cp313-macosx_11_0_arm64.whl (633 kB)\n",
      "Using cached Brotli-1.1.0-cp313-cp313-macosx_10_13_universal2.whl (815 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.1.1-cp313-cp313-macosx_11_0_universal2.whl (272 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading llama_cloud_services-0.6.1-py3-none-any.whl (22 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: webencodings, text-unidecode, striprtf, pytz, mpmath, filetype, dirtyjson, brotli, zstandard, zipp, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, sympy, soupsieve, socksio, sniffio, setuptools, regex, PyYAML, python-slugify, python-dotenv, pypdf, pyparsing, propcache, pillow, pathspec, orjson, numpy, networkx, mypy-extensions, multidict, msgpack, marshmallow, MarkupSafe, lxml, kiwisolver, jsonpointer, joblib, jiter, idna, hyperframe, hpack, h11, greenlet, fsspec, frozenlist, fonttools, filelock, fastavro, distro, cycler, colorlog, click, charset-normalizer, certifi, bleach, backoff, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, scipy, requests, pydantic-core, pandas, nltk, jsonpatch, jinja2, importlib_metadata, httpcore, h2, deprecated, contourpy, black, beautifulsoup4, anyio, aiosignal, torch, tiktoken, requests-toolbelt, pydantic, matplotlib, kaggle, httpx, dataclasses-json, aiohttp, openai, ollama, llama-index-core, llama-cloud, langsmith, langgraph-sdk, cohere, semantic-router, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, langchain-core, duckduckgo-search, llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, langgraph-checkpoint, langchain-text-splitters, llama-index-readers-llama-parse, llama-index-program-openai, langgraph, langchain, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 SQLAlchemy-2.0.38 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 attrs-25.1.0 backoff-2.2.1 beautifulsoup4-4.13.3 black-23.12.1 bleach-6.2.0 brotli-1.1.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 cohere-4.57 colorlog-6.9.0 contourpy-1.3.1 cycler-0.12.1 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 distro-1.9.0 duckduckgo-search-7.4.4 fastavro-1.10.0 filelock-3.17.0 filetype-1.2.0 fonttools-4.56.0 frozenlist-1.5.0 fsspec-2025.2.0 greenlet-3.1.1 h11-0.14.0 h2-4.2.0 hpack-4.1.0 httpcore-1.0.7 httpx-0.28.1 hyperframe-6.1.0 idna-3.10 importlib_metadata-6.11.0 jinja2-3.1.5 jiter-0.8.2 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 kaggle-1.6.17 kiwisolver-1.4.8 langchain-0.3.19 langchain-core-0.3.37 langchain-text-splitters-0.3.6 langgraph-0.2.74 langgraph-checkpoint-2.0.16 langgraph-sdk-0.1.53 langsmith-0.3.10 llama-cloud-0.1.13 llama-cloud-services-0.6.1 llama-index-0.12.19 llama-index-agent-openai-0.4.6 llama-index-cli-0.4.0 llama-index-core-0.12.19 llama-index-embeddings-openai-0.3.1 llama-index-indices-managed-llama-cloud-0.6.8 llama-index-llms-openai-0.3.20 llama-index-multi-modal-llms-openai-0.4.3 llama-index-program-openai-0.3.1 llama-index-question-gen-openai-0.3.0 llama-index-readers-file-0.4.5 llama-index-readers-llama-parse-0.4.0 llama-parse-0.6.1 lxml-5.3.1 marshmallow-3.26.1 matplotlib-3.10.0 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 numpy-1.26.4 ollama-0.4.7 openai-1.63.2 orjson-3.10.15 pandas-2.2.3 pathspec-0.12.1 pillow-11.1.0 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 pyparsing-3.2.1 pypdf-5.3.0 python-dotenv-1.0.1 python-slugify-8.0.4 pytz-2025.1 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 scipy-1.15.2 semantic-router-0.0.20 setuptools-75.8.0 sniffio-1.3.1 socksio-1.0.0 soupsieve-2.6 striprtf-0.0.26 sympy-1.13.1 tenacity-9.0.0 text-unidecode-1.3 tiktoken-0.9.0 torch-2.6.0 tqdm-4.67.1 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2025.1 urllib3-2.3.0 webencodings-0.5.1 wrapt-1.17.2 yarl-1.18.3 zipp-3.21.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News API 823e1b0648fd4d51b6992ce47b84b38e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
